# DICOMO 2023 シンポジウム
# 生成AIの現状と展望 -AIと共生する未来への道程-

## 参考文献:

### Section1
* Scaling Laws for Neural Language Models (2020): https://arxiv.org/abs/2001.08361
* Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM (2021): https://arxiv.org/abs/2104.04473
* ChatGPTの学習ステップ: https://openai.com/blog/chatgpt

### Section2
* Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (2022): https://arxiv.org/abs/2201.11903
* チャットボットWebアプリのコード: https://github.com/yukinaga/chatgpt_api/
* Can Large Language Models Infer Causation from Correlation? (2023): https://arxiv.org/abs/2306.05836
* GPT best practices: https://platform.openai.com/docs/guides/gpt-best-practices/

### Section3
* 弁護士ドットコムのアンケート結果: https://dime.jp/genre/1588882/

### Section4
* ChatGPTに感情回路を埋め込んだら、やべぇ感じになった: https://note.com/fladdict/n/n5043e6e61ce3
* Theory of Mind May Have Spontaneously Emerged in Large Language Models (2023): https://arxiv.org/abs/2302.02083
* Generative Agents: Interactive Simulacra of Human Behavior (2023): https://arxiv.org/abs/2304.03442
